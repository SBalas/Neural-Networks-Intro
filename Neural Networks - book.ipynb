{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nerual Networks and Deep Learning\n",
    "http://neuralnetworksanddeeplearning.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Chapter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 10\n",
      "2 20\n",
      "3 30\n",
      "\n",
      "\n",
      "[3, 1]\n",
      "[2, 3]\n",
      "\n",
      "\n",
      "[[ 0.63120294  0.58595542]\n",
      " [ 0.51456038 -1.60393383]\n",
      " [ 0.80537377 -0.76728474]]\n",
      "[[ 1.06862833 -0.43638407  0.23084483]]\n",
      "\n",
      "\n",
      "[1, 2] [1]\n",
      "[10, 20] [2]\n",
      "[100, 200] [3]\n"
     ]
    }
   ],
   "source": [
    "# zip function\n",
    "\n",
    "a = [1,2,3]\n",
    "b = [10,20,30]\n",
    "for i, j in (zip(a,b)):\n",
    "    print(i,j)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "sizes = [2,3,1]\n",
    "print(sizes[1:])\n",
    "print(sizes[:-1])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for x, y in (zip(sizes[:-1], sizes[1:])):\n",
    "    print(np.random.randn(y, x))\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "zz = ([[1,2], [10,20], [100,200]])\n",
    "yy = ([[1], [2], [3]])\n",
    "for x, z in zip(zz,yy):\n",
    "    print(x,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize network\n",
    "- The class takes in the size of the network. For example ```Network([2,3,1])``` has three layers with number of nodes in each layer. Layers are L0, L1, L2\n",
    "- Class initalizes the size and number of layers\n",
    "- **Biases**\n",
    "    - It also assigns biases for each of the nodes starting from the L1 since L0 the input later. ```self.biases``` gives a list with ```length = number of layers - 1```. \n",
    "    - L0 = Input layer\n",
    "    - L1 = Three nodes and three biases\n",
    "    - L2 = One node and one bias\n",
    "- **Weights**\n",
    "    - From L0 to L1, two neurons go into three, so six weights are assigned. (3,2) matrix of weights\n",
    "    - From L1 to L2, three neurons go into one, so three weights are assigned. (1,3) matrix of weights\n",
    "- $\\mathbf {wX + b}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 1]\n",
      "[array([[ 1.54715131],\n",
      "       [-0.21973541],\n",
      "       [-1.03595682]]), array([[0.57378319]])]\n",
      "[array([[ 0.94154949, -0.43965656],\n",
      "       [ 0.95935638, -0.08165227],\n",
      "       [ 0.94874439, -0.33314255]]), array([[ 1.52501084, -0.93080075,  0.38855133]])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.52501084, -0.93080075,  0.38855133]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Network(object):\n",
    "    def __init__(self, sizes):\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        \n",
    "\n",
    "net = Network([2,3,1])\n",
    "print(net.sizes)\n",
    "print(net.biases)\n",
    "print(net.weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0 + np.exp(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the feedforward method, which gives the sigmoid output for a given input**\n",
    "- This takes matrices w, A, and b and applies the sigma function to it.\n",
    "- $\\sigma(\\mathbf {wA + b})$\n",
    "- A is an (n,1) matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(self, a):\n",
    "    for b, w in zip(self.biases, self, weights):\n",
    "        a = sigmoid(np.dot(w,a) + b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mnist_loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-ed4c15e41906>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmnist_loader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mnist_loader'"
     ]
    }
   ],
   "source": [
    "import mnist_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
